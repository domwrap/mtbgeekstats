{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI MTB DH Data Retrieval\n",
    "\n",
    "## Setup\n",
    "#### Import Libraries\n",
    "\n",
    "If you do not have these libraries available, you should install them using `pip`\n",
    "\n",
    "```\n",
    "pip install requests\n",
    "pip install bs4\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Which race data are we collecting?\n",
    "\n",
    "1. Losinj\n",
    "1. Fort William\n",
    "1. Leogang\n",
    "1. Val di Sole\n",
    "1. Vallnord\n",
    "1. Mont-Sainte-Anne\n",
    "1. La Bresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = 1\n",
    "gender = 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Sources\n",
    "\n",
    "The UCI Live Timing API contains a lot of data points, but not all the ones we want (speed being the main one missing), and not even all the ones they include on their own PDF which is frustrating.\n",
    "\n",
    "Similarly, Roots & Rain also has a lot of the data points, but again not all of them; most notably it's missing timing splits 4 and 5.\n",
    "\n",
    "Therefore we need to pull from both sources and combine the sets.\n",
    "\n",
    "Here we specify the URLs for both sources from which we will extract our data. The UCI API URL can be found by loading the Live Timing page then using your browser's inspector on the Network tab (in Chrome at least) to see the data feed. As the UCI seems to be using a Single Page Application (SPA) here, it's not straight forward to extract this link automagically.\n",
    "\n",
    "*Links will be added as data sources become available.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = [\n",
    "    [\n",
    "        'losinj',\n",
    "         'http://prod.chronorace.be/api/results/uci/dh/race/20180421_dh/3',\n",
    "         'https://www.rootsandrain.com/race5897/2018-apr-22-mercedes-benz-uci-world-cup-1-losinj/results/filters/m/',\n",
    "         'http://prod.chronorace.be/api/results/uci/dh/race/20180421_dh/6',\n",
    "         'https://www.rootsandrain.com/race5897/2018-apr-22-mercedes-benz-uci-world-cup-1-losinj/results/filters/f/'\n",
    "    ]\n",
    "    , [ 'fortbill', '', '' ]\n",
    "    , [ 'leogang', '', '' ]\n",
    "    , [ 'valdisole', '', '' ]\n",
    "    , [ 'vallnord', '', '' ]\n",
    "    , [ 'msa', '', '' ]\n",
    "    , [ 'labresse', '', '' ]\n",
    "]\n",
    "key = 0 if gender == 'm' else 2\n",
    "raceName = races[race-1][0]\n",
    "urlUci = races[race-1][key+1]\n",
    "urlRoots = races[race-1][key+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI API\n",
    "### Load Data\n",
    "\n",
    "These two lines make the actual request to the server, and then converts the JSON string response in to a usable list format (deserialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get( urlUci )\n",
    "d = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API returns with three main sections:\n",
    "\n",
    "1. `Last Finisher`\n",
    " - Racers in order of start time\n",
    "2. `Results`\n",
    " - Racers in finishing rank order\n",
    "3. `Riders`\n",
    " - Personal details on all racers\n",
    " \n",
    "Each contains many data points. To see all the contained data, you can un-comment and execute any of the lines in the next section to explore more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display( d )\n",
    "# display( d['Results'][7] )\n",
    "# display( d['Riders']['1034'] )\n",
    "# display( d['Results'][61] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "\n",
    "Here we iterate over the `Results` sub-set of data to extract the information we care about: basically those that finished the race, some identifying info, and their splits.\n",
    "\n",
    "If you looked at detail of the returned data set in the last step you might have noticed the rider's name is not stored next to their result, riders are only identified by a reference number. To facilitate our analysis later on it is useful to import each rider's name at this stage by cross-referencing the `Riders` sub-set.\n",
    "\n",
    "We start with an empty list `lst` and in each loop iteration add an entry (actually a dict) to that list for each rider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for idx, row in enumerate( d['Results'] ):\n",
    "    fin = \"Finished\" == row['Status']\n",
    "    res = {\n",
    "        'rank': row['Position']  if fin else idx+1,\n",
    "        'name': d['Riders'][str(row['RaceNr'])]['PrintName'],\n",
    "        'id': row['RaceNr'],\n",
    "        'uci': d['Riders'][str(row['RaceNr'])]['UciRiderId'],\n",
    "        'bib': d['Riders'][str(row['RaceNr'])]['RaceNr'],\n",
    "        'status': row['Status'],\n",
    "        'speed': np.nan,\n",
    "        'split1': row['Times'][0]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split2': row['Times'][1]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split3': row['Times'][2]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split4': row['Times'][3]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split5': row['Times'][4]['RaceTime']/1000 if fin else np.nan,\n",
    "    }\n",
    "\n",
    "    lst.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line loads the completed list in to a Pandas dataframe so that we can easily write it out to CSV later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( lst )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at our data at this point to make sure it looks how we expect.\n",
    "\n",
    "At this point the `speed` column is NaN (Not a Number) for all racers. This will be filled in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bib</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>speed</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>status</th>\n",
       "      <th>uci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>GWIN Aaron</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.810</td>\n",
       "      <td>52.860</td>\n",
       "      <td>80.785</td>\n",
       "      <td>116.514</td>\n",
       "      <td>139.193</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10006516663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1013</td>\n",
       "      <td>SHAW Luca</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.613</td>\n",
       "      <td>54.162</td>\n",
       "      <td>82.787</td>\n",
       "      <td>118.094</td>\n",
       "      <td>139.991</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10008813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1016</td>\n",
       "      <td>LUCAS Dean</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.680</td>\n",
       "      <td>53.964</td>\n",
       "      <td>81.870</td>\n",
       "      <td>117.830</td>\n",
       "      <td>140.328</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10008103322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1019</td>\n",
       "      <td>BLENKINSOP Samuel</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.224</td>\n",
       "      <td>54.699</td>\n",
       "      <td>82.891</td>\n",
       "      <td>118.749</td>\n",
       "      <td>141.107</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10004485929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1034</td>\n",
       "      <td>NORTON Dakotah</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.904</td>\n",
       "      <td>54.898</td>\n",
       "      <td>83.172</td>\n",
       "      <td>119.061</td>\n",
       "      <td>141.821</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10010038167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bib    id               name  rank  speed  split1  split2  split3   split4  \\\n",
       "0    1  1001         GWIN Aaron     1    NaN  20.810  52.860  80.785  116.514   \n",
       "1   13  1013          SHAW Luca     2    NaN  20.613  54.162  82.787  118.094   \n",
       "2   16  1016         LUCAS Dean     3    NaN  20.680  53.964  81.870  117.830   \n",
       "3   19  1019  BLENKINSOP Samuel     4    NaN  21.224  54.699  82.891  118.749   \n",
       "4   34  1034     NORTON Dakotah     5    NaN  20.904  54.898  83.172  119.061   \n",
       "\n",
       "    split5    status          uci  \n",
       "0  139.193  Finished  10006516663  \n",
       "1  139.991  Finished  10008813442  \n",
       "2  140.328  Finished  10008103322  \n",
       "3  141.107  Finished  10004485929  \n",
       "4  141.821  Finished  10010038167  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the personal information about each racer is much easier as we can just export the entire `Riders` dataset. However, the rows and columns are the wrong way round so the `.T` command *transposes* the information, meaning it basically flips the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame( d['Riders'] )\n",
    "df2 = df2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can glimpse the first few rows of our `DataFrame` and can check the data looks as we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>CategoryCode</th>\n",
       "      <th>FamilyName</th>\n",
       "      <th>GivenName</th>\n",
       "      <th>Id</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Outfit</th>\n",
       "      <th>PrintName</th>\n",
       "      <th>RaceId</th>\n",
       "      <th>RaceNr</th>\n",
       "      <th>ScoreboardName</th>\n",
       "      <th>StartOrder</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>UciCode</th>\n",
       "      <th>UciRank</th>\n",
       "      <th>UciRiderId</th>\n",
       "      <th>UciTeamCode</th>\n",
       "      <th>UciTeamId</th>\n",
       "      <th>UciTeamName</th>\n",
       "      <th>WorldCupRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1987-12-24T00:00:00</td>\n",
       "      <td>ME</td>\n",
       "      <td>GWIN</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>101001</td>\n",
       "      <td>USA</td>\n",
       "      <td>NCh</td>\n",
       "      <td>GWIN Aaron</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GWIN A</td>\n",
       "      <td>63</td>\n",
       "      <td>55620000</td>\n",
       "      <td>USA19871224</td>\n",
       "      <td>1</td>\n",
       "      <td>10006516663</td>\n",
       "      <td>YTM</td>\n",
       "      <td>1531</td>\n",
       "      <td>THE YT MOB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1993-07-13T00:00:00</td>\n",
       "      <td>ME</td>\n",
       "      <td>BROSNAN</td>\n",
       "      <td>Troy</td>\n",
       "      <td>101002</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NCh</td>\n",
       "      <td>BROSNAN Troy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BROSNAN T</td>\n",
       "      <td>62</td>\n",
       "      <td>55410000</td>\n",
       "      <td>AUS19930713</td>\n",
       "      <td>2</td>\n",
       "      <td>10007307417</td>\n",
       "      <td>CFT</td>\n",
       "      <td>2162</td>\n",
       "      <td>CANYON FACTORY DOWNHILL TEAM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1981-11-13T00:00:00</td>\n",
       "      <td>ME</td>\n",
       "      <td>MINNAAR</td>\n",
       "      <td>Greg</td>\n",
       "      <td>101003</td>\n",
       "      <td>RSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MINNAAR Greg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MINNAAR G</td>\n",
       "      <td>55</td>\n",
       "      <td>53940000</td>\n",
       "      <td>RSA19811113</td>\n",
       "      <td>5</td>\n",
       "      <td>10002818640</td>\n",
       "      <td>SCB</td>\n",
       "      <td>1307</td>\n",
       "      <td>SANTA CRUZ SYNDICATE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1994-05-13T00:00:00</td>\n",
       "      <td>ME</td>\n",
       "      <td>BRUNI</td>\n",
       "      <td>Loic</td>\n",
       "      <td>101004</td>\n",
       "      <td>FRA</td>\n",
       "      <td>WCh</td>\n",
       "      <td>BRUNI Loic</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>BRUNI L</td>\n",
       "      <td>47</td>\n",
       "      <td>52320000</td>\n",
       "      <td>FRA19940513</td>\n",
       "      <td>3</td>\n",
       "      <td>10007544358</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1667</td>\n",
       "      <td>SPECIALIZED GRAVITY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1996-05-07T00:00:00</td>\n",
       "      <td>ME</td>\n",
       "      <td>VERGIER</td>\n",
       "      <td>Loris</td>\n",
       "      <td>101005</td>\n",
       "      <td>FRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VERGIER Loris</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>VERGIER L</td>\n",
       "      <td>49</td>\n",
       "      <td>52680000</td>\n",
       "      <td>FRA19960507</td>\n",
       "      <td>7</td>\n",
       "      <td>10008723112</td>\n",
       "      <td>SCB</td>\n",
       "      <td>1307</td>\n",
       "      <td>SANTA CRUZ SYNDICATE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BirthDate CategoryCode FamilyName GivenName      Id Nation  \\\n",
       "1001  1987-12-24T00:00:00           ME       GWIN     Aaron  101001    USA   \n",
       "1002  1993-07-13T00:00:00           ME    BROSNAN      Troy  101002    AUS   \n",
       "1003  1981-11-13T00:00:00           ME    MINNAAR      Greg  101003    RSA   \n",
       "1004  1994-05-13T00:00:00           ME      BRUNI      Loic  101004    FRA   \n",
       "1005  1996-05-07T00:00:00           ME    VERGIER     Loris  101005    FRA   \n",
       "\n",
       "     Outfit      PrintName RaceId RaceNr ScoreboardName StartOrder StartTime  \\\n",
       "1001    NCh     GWIN Aaron      0      1         GWIN A         63  55620000   \n",
       "1002    NCh   BROSNAN Troy      0      2      BROSNAN T         62  55410000   \n",
       "1003    NaN   MINNAAR Greg      0      3      MINNAAR G         55  53940000   \n",
       "1004    WCh     BRUNI Loic      0      4        BRUNI L         47  52320000   \n",
       "1005    NaN  VERGIER Loris      0      5      VERGIER L         49  52680000   \n",
       "\n",
       "          UciCode UciRank   UciRiderId UciTeamCode UciTeamId  \\\n",
       "1001  USA19871224       1  10006516663         YTM      1531   \n",
       "1002  AUS19930713       2  10007307417         CFT      2162   \n",
       "1003  RSA19811113       5  10002818640         SCB      1307   \n",
       "1004  FRA19940513       3  10007544358         SGR      1667   \n",
       "1005  FRA19960507       7  10008723112         SCB      1307   \n",
       "\n",
       "                       UciTeamName WorldCupRank  \n",
       "1001                    THE YT MOB            1  \n",
       "1002  CANYON FACTORY DOWNHILL TEAM            2  \n",
       "1003          SANTA CRUZ SYNDICATE            3  \n",
       "1004           SPECIALIZED GRAVITY            4  \n",
       "1005          SANTA CRUZ SYNDICATE            5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df2.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roots and Rain\n",
    "### Load Data\n",
    "\n",
    "Similar to the UCI api, we make a request to the server with the previously declared `urlRoots` variable. This time however we simply load the content of the response as text which is actually the HTML code of the web page. We do not do have a nice JSON API to read which means we will not deserialize.\n",
    "\n",
    "Next we invoke a utility called `BeautifulSoup` to help us extract the data from this messy HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post( urlRoots )\n",
    "c = r.content\n",
    "soup = BeautifulSoup( c, \"html.parser\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "\n",
    "If you look at the Roots and Rain page you'll see it listed in a tabular format. What we do here is find all the rows of that table so we can extract the information we need.\n",
    "\n",
    "Specifically we are looking for instances of `tr` (table row), with a class that *begins with* `c-` as this is a common denomenator I discovered when looking through the code with the browser inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find_all( \"tr\", class_=lambda x: x and 'c-' in x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the UCI data set, here we will iterate over each row in our data set--basically each table row from the web page--and extract the bits we need.\n",
    "\n",
    "Racer speed is the metric we're interested in, but in order to match that to our existing data set we need a corresponding identifier so we also extract the racer licence number as that exists in both sets and we can match them together: it is the *intersect* between both sets of data.\n",
    "\n",
    "To summarise:\n",
    "1. Extract licence number and corresponding speed\n",
    "2. Import speed to existing DataFrame matching racers by licence\n",
    "\n",
    "The `if` condition in the middle will exit this block of code once we hit the end of the Elite finishers, seeing as that's all we have in our existing data set so can't match anyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    cells = row.find_all( \"td\" )\n",
    "\n",
    "    speed = cells[7].text[:5]\n",
    "    licence = cells[4].text\n",
    "    bib = int( cells[1].text )\n",
    "    pos = cells[0].text[8:]\n",
    "    if \"\" == pos: break\n",
    "    # Match rider by UCI licence if present, otherwise fallback to bib\n",
    "    if len(df2.loc[df2['UciRiderId'] == licence].index.values ):\n",
    "        rid = int(df2.loc[df2['UciRiderId'] == licence].index.values[0])\n",
    "    else:\n",
    "        rid = int( df2.loc[df2['RaceNr'] == bib].index.values[0] )\n",
    "    df.loc[df['id'] == rid, 'speed'] = speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can take another look at how our data is looking, with the `speed` column now containing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bib</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>speed</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>status</th>\n",
       "      <th>uci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>GWIN Aaron</td>\n",
       "      <td>1</td>\n",
       "      <td>47.21</td>\n",
       "      <td>20.810</td>\n",
       "      <td>52.860</td>\n",
       "      <td>80.785</td>\n",
       "      <td>116.514</td>\n",
       "      <td>139.193</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10006516663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1013</td>\n",
       "      <td>SHAW Luca</td>\n",
       "      <td>2</td>\n",
       "      <td>49.60</td>\n",
       "      <td>20.613</td>\n",
       "      <td>54.162</td>\n",
       "      <td>82.787</td>\n",
       "      <td>118.094</td>\n",
       "      <td>139.991</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10008813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1016</td>\n",
       "      <td>LUCAS Dean</td>\n",
       "      <td>3</td>\n",
       "      <td>48.00</td>\n",
       "      <td>20.680</td>\n",
       "      <td>53.964</td>\n",
       "      <td>81.870</td>\n",
       "      <td>117.830</td>\n",
       "      <td>140.328</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10008103322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1019</td>\n",
       "      <td>BLENKINSOP Samuel</td>\n",
       "      <td>4</td>\n",
       "      <td>49.55</td>\n",
       "      <td>21.224</td>\n",
       "      <td>54.699</td>\n",
       "      <td>82.891</td>\n",
       "      <td>118.749</td>\n",
       "      <td>141.107</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10004485929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1034</td>\n",
       "      <td>NORTON Dakotah</td>\n",
       "      <td>5</td>\n",
       "      <td>47.50</td>\n",
       "      <td>20.904</td>\n",
       "      <td>54.898</td>\n",
       "      <td>83.172</td>\n",
       "      <td>119.061</td>\n",
       "      <td>141.821</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10010038167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bib    id               name  rank  speed  split1  split2  split3   split4  \\\n",
       "0    1  1001         GWIN Aaron     1  47.21  20.810  52.860  80.785  116.514   \n",
       "1   13  1013          SHAW Luca     2  49.60  20.613  54.162  82.787  118.094   \n",
       "2   16  1016         LUCAS Dean     3  48.00  20.680  53.964  81.870  117.830   \n",
       "3   19  1019  BLENKINSOP Samuel     4  49.55  21.224  54.699  82.891  118.749   \n",
       "4   34  1034     NORTON Dakotah     5  47.50  20.904  54.898  83.172  119.061   \n",
       "\n",
       "    split5    status          uci  \n",
       "0  139.193  Finished  10006516663  \n",
       "1  139.991  Finished  10008813442  \n",
       "2  140.328  Finished  10008103322  \n",
       "3  141.107  Finished  10004485929  \n",
       "4  141.821  Finished  10010038167  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export\n",
    "\n",
    "All that's left is to save our data to CSV files so we can quickly import it again for analysis and visualization without making constant requests to the online servers. This not only reduces load on the services providing the data, but also allows us to work on our analysis \"offline\", moreover giving us a local copy in case the results are ever taken down. It's also much quicker to load data this way than constantly hitting online servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv( str(race) + '_' + raceName + '_' + gender + '.results.csv' )\n",
    "df2.to_csv( str(race) + '_' + raceName + '_' + gender + '.racers.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Credits\n",
    "\n",
    "### Author: Dominic Wrapson\n",
    "\n",
    "\n",
    "> **@domwrap**\n",
    "<br>\n",
    "<img src=\"https://png.icons8.com/material/24/000000/github-2.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/stackoverflow.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/linkedin.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/windows8.png\">\n",
    "<img src=\"https://png.icons8.com/ios-glyphs/24/000000/instagram-new.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/twitter.png\">\n",
    "<a href=\"https://medium.com/@domwrap\"><img src=\"https://png.icons8.com/material/24/000000/medium-logo.png\"></a>\n",
    ">\n",
    "> <img src=\"https://png.icons8.com/material/24/000000/home.png\"> http://dominic.wrapson.com\n",
    ">\n",
    "><img src=\"https://png.icons8.com/material/24/000000/cycling-mountain-bike.png\"> [Hwulex](https://www.pinkbike.com/u/Hwulex/)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Special Thanks\n",
    "\n",
    "Mark Shilton for the inspiration\n",
    "- http://lookatthestats.blogspot.ca\n",
    "- https://plus.google.com/+MarkShilton\n",
    "- https://dirtmountainbike.com/author/mrgeekstats\n",
    "\n",
    "\n",
    "<a href=\"https://icons8.com\">Icon pack by Icons8</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
