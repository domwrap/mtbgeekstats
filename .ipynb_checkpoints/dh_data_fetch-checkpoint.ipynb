{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI MTB DH Data Retrieval\n",
    "\n",
    "## Setup\n",
    "#### Import Libraries\n",
    "\n",
    "If you do not have these libraries available, you should install them using `pip`\n",
    "\n",
    "```\n",
    "pip install requests\n",
    "pip install bs4\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Which race data are we collecting?\n",
    "\n",
    "1. Losinj\n",
    "1. Fort William\n",
    "1. Leogang\n",
    "1. Val di Sole\n",
    "1. Vallnord\n",
    "1. Mont-Sainte-Anne\n",
    "1. La Bresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = 1\n",
    "gender = 'f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Sources\n",
    "\n",
    "The UCI Live Timing API contains a lot of data points, but not all the ones we want (speed being the main one missing), and not even all the ones they include on their own PDF which is frustrating.\n",
    "\n",
    "Similarly, Roots & Rain also has a lot of the data points, but again not all of them; most notably it's missing timing splits 4 and 5.\n",
    "\n",
    "Therefore we need to pull from both sources and combine the sets.\n",
    "\n",
    "Here we specify the URLs for both sources from which we will extract our data. The UCI API URL can be found by loading the Live Timing page then using your browser's inspector on the Network tab (in Chrome at least) to see the data feed. As the UCI seems to be using a Single Page Application (SPA) here, it's not straight forward to extract this link automagically.\n",
    "\n",
    "*Links will be added as data sources become available.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = [\n",
    "    [\n",
    "        'losinj',\n",
    "         'http://prod.chronorace.be/api/results/uci/dh/race/20180421_dh/3',\n",
    "         'https://www.rootsandrain.com/race5897/2018-apr-22-mercedes-benz-uci-world-cup-1-losinj/results/filters/m/',\n",
    "         'http://prod.chronorace.be/api/results/uci/dh/race/20180421_dh/6',\n",
    "         'https://www.rootsandrain.com/race5897/2018-apr-22-mercedes-benz-uci-world-cup-1-losinj/results/filters/f/'\n",
    "    ]\n",
    "    , [ 'fortbill', '', '' ]\n",
    "    , [ 'leogang', '', '' ]\n",
    "    , [ 'valdisole', '', '' ]\n",
    "    , [ 'vallnord', '', '' ]\n",
    "    , [ 'msa', '', '' ]\n",
    "    , [ 'labresse', '', '' ]\n",
    "]\n",
    "key = 0 if gender == 'm' else 2\n",
    "raceName = races[race-1][0]\n",
    "urlUci = races[race-1][key+1]\n",
    "urlRoots = races[race-1][key+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI API\n",
    "### Load Data\n",
    "\n",
    "These two lines make the actual request to the server, and then converts the JSON string response in to a usable list format (deserialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get( urlUci )\n",
    "d = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API returns with three main sections:\n",
    "\n",
    "1. `Last Finisher`\n",
    " - Racers in order of start time\n",
    "2. `Results`\n",
    " - Racers in finishing rank order\n",
    "3. `Riders`\n",
    " - Personal details on all racers\n",
    " \n",
    "Each contains many data points. To see all the contained data, you can un-comment and execute any of the lines in the next section to explore more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display( d )\n",
    "# display( d['Results'][7] )\n",
    "# display( d['Riders']['1034'] )\n",
    "# display( d['Results'][61] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "\n",
    "Here we iterate over the `Results` sub-set of data to extract the information we care about: basically those that finished the race, some identifying info, and their splits.\n",
    "\n",
    "If you looked at detail of the returned data set in the last step you might have noticed the rider's name is not stored next to their result, riders are only identified by a reference number. To facilitate our analysis later on it is useful to import each rider's name at this stage by cross-referencing the `Riders` sub-set.\n",
    "\n",
    "We start with an empty list `lst` and in each loop iteration add an entry (actually a dict) to that list for each rider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for idx, row in enumerate( d['Results'] ):\n",
    "    fin = \"Finished\" == row['Status']\n",
    "    res = {\n",
    "        'rank': row['Position']  if fin else idx+1,\n",
    "        'name': d['Riders'][str(row['RaceNr'])]['PrintName'],\n",
    "        'id': row['RaceNr'],\n",
    "        'uci': d['Riders'][str(row['RaceNr'])]['UciRiderId'],\n",
    "        'bib': d['Riders'][str(row['RaceNr'])]['RaceNr'],\n",
    "        'status': row['Status'],\n",
    "        'speed': np.nan,\n",
    "        'split1': row['Times'][0]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split2': row['Times'][1]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split3': row['Times'][2]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split4': row['Times'][3]['RaceTime']/1000 if fin else np.nan,\n",
    "        'split5': row['Times'][4]['RaceTime']/1000 if fin else np.nan,\n",
    "    }\n",
    "\n",
    "    lst.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line loads the completed list in to a Pandas dataframe so that we can easily write it out to CSV later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( lst )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at our data at this point to make sure it looks how we expect.\n",
    "\n",
    "At this point the `speed` column is NaN (Not a Number) for all racers. This will be filled in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bib</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>speed</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>status</th>\n",
       "      <th>uci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>NICOLE Myriam</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.472</td>\n",
       "      <td>60.224</td>\n",
       "      <td>92.252</td>\n",
       "      <td>135.352</td>\n",
       "      <td>160.706</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10004535237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>ATHERTON Rachel</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.847</td>\n",
       "      <td>61.748</td>\n",
       "      <td>95.397</td>\n",
       "      <td>139.415</td>\n",
       "      <td>164.265</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10003434487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>SEAGRAVE Tahnee</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.902</td>\n",
       "      <td>61.248</td>\n",
       "      <td>95.686</td>\n",
       "      <td>139.696</td>\n",
       "      <td>164.484</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10007414016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>CABIROU Marine</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.295</td>\n",
       "      <td>63.484</td>\n",
       "      <td>97.391</td>\n",
       "      <td>140.362</td>\n",
       "      <td>165.935</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10009563069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2028</td>\n",
       "      <td>RAVANEL Cecile</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.986</td>\n",
       "      <td>63.606</td>\n",
       "      <td>97.407</td>\n",
       "      <td>142.042</td>\n",
       "      <td>168.416</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10002816317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bib    id             name  rank  speed  split1  split2  split3   split4  \\\n",
       "0    1  2001    NICOLE Myriam     1    NaN  23.472  60.224  92.252  135.352   \n",
       "1    4  2004  ATHERTON Rachel     2    NaN  22.847  61.748  95.397  139.415   \n",
       "2    2  2002  SEAGRAVE Tahnee     3    NaN  22.902  61.248  95.686  139.696   \n",
       "3    8  2008   CABIROU Marine     4    NaN  24.295  63.484  97.391  140.362   \n",
       "4   28  2028   RAVANEL Cecile     5    NaN  24.986  63.606  97.407  142.042   \n",
       "\n",
       "    split5    status          uci  \n",
       "0  160.706  Finished  10004535237  \n",
       "1  164.265  Finished  10003434487  \n",
       "2  164.484  Finished  10007414016  \n",
       "3  165.935  Finished  10009563069  \n",
       "4  168.416  Finished  10002816317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the personal information about each racer is much easier as we can just export the entire `Riders` dataset. However, the rows and columns are the wrong way round so the `.T` command *transposes* the information, meaning it basically flips the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame( d['Riders'] )\n",
    "df2 = df2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can glimpse the first few rows of our `DataFrame` and can check the data looks as we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>CategoryCode</th>\n",
       "      <th>FamilyName</th>\n",
       "      <th>GivenName</th>\n",
       "      <th>Id</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Outfit</th>\n",
       "      <th>PrintName</th>\n",
       "      <th>RaceId</th>\n",
       "      <th>RaceNr</th>\n",
       "      <th>ScoreboardName</th>\n",
       "      <th>StartOrder</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>UciCode</th>\n",
       "      <th>UciRank</th>\n",
       "      <th>UciRiderId</th>\n",
       "      <th>UciTeamCode</th>\n",
       "      <th>UciTeamId</th>\n",
       "      <th>UciTeamName</th>\n",
       "      <th>WorldCupRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1990-02-08T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>NICOLE</td>\n",
       "      <td>Myriam</td>\n",
       "      <td>102001</td>\n",
       "      <td>FRA</td>\n",
       "      <td>NCh</td>\n",
       "      <td>NICOLE Myriam</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NICOLE M</td>\n",
       "      <td>14</td>\n",
       "      <td>46710000</td>\n",
       "      <td>FRA19900208</td>\n",
       "      <td>1</td>\n",
       "      <td>10004535237</td>\n",
       "      <td>CVN</td>\n",
       "      <td>1590</td>\n",
       "      <td>COMMENCAL / VALLNORD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>1995-06-15T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>SEAGRAVE</td>\n",
       "      <td>Tahnee</td>\n",
       "      <td>102002</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEAGRAVE Tahnee</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SEAGRAVE T</td>\n",
       "      <td>12</td>\n",
       "      <td>46290000</td>\n",
       "      <td>GBR19950615</td>\n",
       "      <td>3</td>\n",
       "      <td>10007414016</td>\n",
       "      <td>FMD</td>\n",
       "      <td>1863</td>\n",
       "      <td>TRANSITION BIKES / MUC-OFF FACTORY RACING</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>1988-06-13T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>HANNAH</td>\n",
       "      <td>Tracey</td>\n",
       "      <td>102003</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NCh</td>\n",
       "      <td>HANNAH Tracey</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>HANNAH T</td>\n",
       "      <td>15</td>\n",
       "      <td>46920000</td>\n",
       "      <td>AUS19880613</td>\n",
       "      <td>2</td>\n",
       "      <td>10003732258</td>\n",
       "      <td>URT</td>\n",
       "      <td>1608</td>\n",
       "      <td>POLYGON UR</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>1987-12-06T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>ATHERTON</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>102004</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NCh</td>\n",
       "      <td>ATHERTON Rachel</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ATHERTON R</td>\n",
       "      <td>16</td>\n",
       "      <td>47130000</td>\n",
       "      <td>GBR19871206</td>\n",
       "      <td>7</td>\n",
       "      <td>10003434487</td>\n",
       "      <td>TDH</td>\n",
       "      <td>1598</td>\n",
       "      <td>TREK FACTORY RACING DH</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1986-09-19T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>SIEGENTHALER</td>\n",
       "      <td>Emilie</td>\n",
       "      <td>102005</td>\n",
       "      <td>SUI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEGENTHALER Emilie</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>SIEGENTHALER</td>\n",
       "      <td>11</td>\n",
       "      <td>46080000</td>\n",
       "      <td>SUI19860919</td>\n",
       "      <td>6</td>\n",
       "      <td>10004167243</td>\n",
       "      <td>PFR</td>\n",
       "      <td>1864</td>\n",
       "      <td>PIVOT FACTORY RACING</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1997-03-12T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>CABIROU</td>\n",
       "      <td>Marine</td>\n",
       "      <td>102008</td>\n",
       "      <td>FRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CABIROU Marine</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>CABIROU M</td>\n",
       "      <td>13</td>\n",
       "      <td>46500000</td>\n",
       "      <td>FRA19970312</td>\n",
       "      <td>5</td>\n",
       "      <td>10009563069</td>\n",
       "      <td>VVR</td>\n",
       "      <td>2096</td>\n",
       "      <td>VOULVOUL RACING</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1990-03-02T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>MILLER</td>\n",
       "      <td>Miranda</td>\n",
       "      <td>102009</td>\n",
       "      <td>CAN</td>\n",
       "      <td>WCh</td>\n",
       "      <td>MILLER Miranda</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>MILLER M</td>\n",
       "      <td>9</td>\n",
       "      <td>45840000</td>\n",
       "      <td>CAN19900302</td>\n",
       "      <td>9</td>\n",
       "      <td>10005872726</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1667</td>\n",
       "      <td>SPECIALIZED GRAVITY</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1991-11-06T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>CAPPELLARI</td>\n",
       "      <td>Carina</td>\n",
       "      <td>102010</td>\n",
       "      <td>SUI</td>\n",
       "      <td>NCh</td>\n",
       "      <td>CAPPELLARI Carina</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>CAPPELLARI C</td>\n",
       "      <td>10</td>\n",
       "      <td>45960000</td>\n",
       "      <td>SUI19911106</td>\n",
       "      <td>11</td>\n",
       "      <td>10006911535</td>\n",
       "      <td>MNR</td>\n",
       "      <td>2039</td>\n",
       "      <td>HIAG DATA - NS-BIKES FACTORY RACING</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1994-05-06T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>SALAZAR</td>\n",
       "      <td>Mariana</td>\n",
       "      <td>102013</td>\n",
       "      <td>ESA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SALAZAR Mariana</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>SALAZAR M</td>\n",
       "      <td>5</td>\n",
       "      <td>45240000</td>\n",
       "      <td>ESA19940506</td>\n",
       "      <td>26</td>\n",
       "      <td>10007687838</td>\n",
       "      <td>DOR</td>\n",
       "      <td>1867</td>\n",
       "      <td>DORVAL AM</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1994-06-07T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>HRASTNIK</td>\n",
       "      <td>Monika</td>\n",
       "      <td>102014</td>\n",
       "      <td>SLO</td>\n",
       "      <td>CCh</td>\n",
       "      <td>HRASTNIK Monika</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>HRASTNIK M</td>\n",
       "      <td>7</td>\n",
       "      <td>45600000</td>\n",
       "      <td>SLO19940607</td>\n",
       "      <td>8</td>\n",
       "      <td>10017602955</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1993-03-08T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>WIDMANN</td>\n",
       "      <td>Veronika</td>\n",
       "      <td>102017</td>\n",
       "      <td>ITA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WIDMANN Veronika</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>WIDMANN V</td>\n",
       "      <td>3</td>\n",
       "      <td>45120000</td>\n",
       "      <td>ITA19930308</td>\n",
       "      <td>17</td>\n",
       "      <td>10007423312</td>\n",
       "      <td>FSF</td>\n",
       "      <td>2238</td>\n",
       "      <td>FS FUNN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1988-02-10T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>RUBESAM</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>102018</td>\n",
       "      <td>GER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUBESAM Sandra</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>RUBESAM S</td>\n",
       "      <td>4</td>\n",
       "      <td>45180000</td>\n",
       "      <td>GER19880210</td>\n",
       "      <td>18</td>\n",
       "      <td>10052523258</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>1998-12-05T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>BATTOLLA</td>\n",
       "      <td>Eva</td>\n",
       "      <td>102025</td>\n",
       "      <td>SUI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BATTOLLA Eva</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>BATTOLLA E</td>\n",
       "      <td>1</td>\n",
       "      <td>45000000</td>\n",
       "      <td>SUI19981205</td>\n",
       "      <td>69</td>\n",
       "      <td>10010936631</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>1993-08-01T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>SCHWEMMER</td>\n",
       "      <td>Kim</td>\n",
       "      <td>102026</td>\n",
       "      <td>GER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCHWEMMER Kim</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>SCHWEMMER K</td>\n",
       "      <td>2</td>\n",
       "      <td>45060000</td>\n",
       "      <td>GER19930801</td>\n",
       "      <td>72</td>\n",
       "      <td>10007401686</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>1981-01-06T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>RAVANEL</td>\n",
       "      <td>Cecile</td>\n",
       "      <td>102028</td>\n",
       "      <td>FRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVANEL Cecile</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>RAVANEL C</td>\n",
       "      <td>8</td>\n",
       "      <td>45720000</td>\n",
       "      <td>FRA19810106</td>\n",
       "      <td>166</td>\n",
       "      <td>10002816317</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>1989-04-27T00:00:00</td>\n",
       "      <td>WE</td>\n",
       "      <td>CURD</td>\n",
       "      <td>Katy</td>\n",
       "      <td>102030</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CURD Katy</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>CURD K</td>\n",
       "      <td>6</td>\n",
       "      <td>45300000</td>\n",
       "      <td>GBR19890427</td>\n",
       "      <td>209</td>\n",
       "      <td>10006044292</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BirthDate CategoryCode    FamilyName GivenName      Id Nation  \\\n",
       "2001  1990-02-08T00:00:00           WE        NICOLE    Myriam  102001    FRA   \n",
       "2002  1995-06-15T00:00:00           WE      SEAGRAVE    Tahnee  102002    GBR   \n",
       "2003  1988-06-13T00:00:00           WE        HANNAH    Tracey  102003    AUS   \n",
       "2004  1987-12-06T00:00:00           WE      ATHERTON    Rachel  102004    GBR   \n",
       "2005  1986-09-19T00:00:00           WE  SIEGENTHALER    Emilie  102005    SUI   \n",
       "2008  1997-03-12T00:00:00           WE       CABIROU    Marine  102008    FRA   \n",
       "2009  1990-03-02T00:00:00           WE        MILLER   Miranda  102009    CAN   \n",
       "2010  1991-11-06T00:00:00           WE    CAPPELLARI    Carina  102010    SUI   \n",
       "2013  1994-05-06T00:00:00           WE       SALAZAR   Mariana  102013    ESA   \n",
       "2014  1994-06-07T00:00:00           WE      HRASTNIK    Monika  102014    SLO   \n",
       "2017  1993-03-08T00:00:00           WE       WIDMANN  Veronika  102017    ITA   \n",
       "2018  1988-02-10T00:00:00           WE       RUBESAM    Sandra  102018    GER   \n",
       "2025  1998-12-05T00:00:00           WE      BATTOLLA       Eva  102025    SUI   \n",
       "2026  1993-08-01T00:00:00           WE     SCHWEMMER       Kim  102026    GER   \n",
       "2028  1981-01-06T00:00:00           WE       RAVANEL    Cecile  102028    FRA   \n",
       "2030  1989-04-27T00:00:00           WE          CURD      Katy  102030    GBR   \n",
       "\n",
       "     Outfit            PrintName RaceId RaceNr ScoreboardName StartOrder  \\\n",
       "2001    NCh        NICOLE Myriam      0      1       NICOLE M         14   \n",
       "2002    NaN      SEAGRAVE Tahnee      0      2     SEAGRAVE T         12   \n",
       "2003    NCh        HANNAH Tracey      0      3       HANNAH T         15   \n",
       "2004    NCh      ATHERTON Rachel      0      4     ATHERTON R         16   \n",
       "2005    NaN  SIEGENTHALER Emilie      0      5   SIEGENTHALER         11   \n",
       "2008    NaN       CABIROU Marine      0      8      CABIROU M         13   \n",
       "2009    WCh       MILLER Miranda      0      9       MILLER M          9   \n",
       "2010    NCh    CAPPELLARI Carina      0     10   CAPPELLARI C         10   \n",
       "2013    NaN      SALAZAR Mariana      0     13      SALAZAR M          5   \n",
       "2014    CCh      HRASTNIK Monika      0     14     HRASTNIK M          7   \n",
       "2017    NaN     WIDMANN Veronika      0     17      WIDMANN V          3   \n",
       "2018    NaN       RUBESAM Sandra      0     18      RUBESAM S          4   \n",
       "2025    NaN         BATTOLLA Eva      0     25     BATTOLLA E          1   \n",
       "2026    NaN        SCHWEMMER Kim      0     26    SCHWEMMER K          2   \n",
       "2028    NaN       RAVANEL Cecile      0     28      RAVANEL C          8   \n",
       "2030    NaN            CURD Katy      0     30         CURD K          6   \n",
       "\n",
       "     StartTime      UciCode UciRank   UciRiderId UciTeamCode UciTeamId  \\\n",
       "2001  46710000  FRA19900208       1  10004535237         CVN      1590   \n",
       "2002  46290000  GBR19950615       3  10007414016         FMD      1863   \n",
       "2003  46920000  AUS19880613       2  10003732258         URT      1608   \n",
       "2004  47130000  GBR19871206       7  10003434487         TDH      1598   \n",
       "2005  46080000  SUI19860919       6  10004167243         PFR      1864   \n",
       "2008  46500000  FRA19970312       5  10009563069         VVR      2096   \n",
       "2009  45840000  CAN19900302       9  10005872726         SGR      1667   \n",
       "2010  45960000  SUI19911106      11  10006911535         MNR      2039   \n",
       "2013  45240000  ESA19940506      26  10007687838         DOR      1867   \n",
       "2014  45600000  SLO19940607       8  10017602955                     0   \n",
       "2017  45120000  ITA19930308      17  10007423312         FSF      2238   \n",
       "2018  45180000  GER19880210      18  10052523258                     0   \n",
       "2025  45000000  SUI19981205      69  10010936631                     0   \n",
       "2026  45060000  GER19930801      72  10007401686                     0   \n",
       "2028  45720000  FRA19810106     166  10002816317                     0   \n",
       "2030  45300000  GBR19890427     209  10006044292                     0   \n",
       "\n",
       "                                    UciTeamName WorldCupRank  \n",
       "2001                       COMMENCAL / VALLNORD            1  \n",
       "2002  TRANSITION BIKES / MUC-OFF FACTORY RACING            2  \n",
       "2003                                 POLYGON UR            3  \n",
       "2004                     TREK FACTORY RACING DH            4  \n",
       "2005                       PIVOT FACTORY RACING            5  \n",
       "2008                            VOULVOUL RACING            8  \n",
       "2009                        SPECIALIZED GRAVITY            9  \n",
       "2010        HIAG DATA - NS-BIKES FACTORY RACING           10  \n",
       "2013                                  DORVAL AM           13  \n",
       "2014                                                      14  \n",
       "2017                                    FS FUNN            0  \n",
       "2018                                                       0  \n",
       "2025                                                       0  \n",
       "2026                                                       0  \n",
       "2028                                                       0  \n",
       "2030                                                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df2.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roots and Rain\n",
    "### Load Data\n",
    "\n",
    "Similar to the UCI api, we make a request to the server with the previously declared `urlRoots` variable. This time however we simply load the content of the response as text which is actually the HTML code of the web page. We do not do have a nice JSON API to read which means we will not deserialize.\n",
    "\n",
    "Next we invoke a utility called `BeautifulSoup` to help us extract the data from this messy HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post( urlRoots )\n",
    "c = r.content\n",
    "soup = BeautifulSoup( c, \"html.parser\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "\n",
    "If you look at the Roots and Rain page you'll see it listed in a tabular format. What we do here is find all the rows of that table so we can extract the information we need.\n",
    "\n",
    "Specifically we are looking for instances of `tr` (table row), with a class that *begins with* `c-` as this is a common denomenator I discovered when looking through the code with the browser inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find_all( \"tr\", class_=lambda x: x and 'c-' in x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the UCI data set, here we will iterate over each row in our data set--basically each table row from the web page--and extract the bits we need.\n",
    "\n",
    "Racer speed is the metric we're interested in, but in order to match that to our existing data set we need a corresponding identifier so we also extract the racer licence number as that exists in both sets and we can match them together: it is the *intersect* between both sets of data.\n",
    "\n",
    "To summarise:\n",
    "1. Extract licence number and corresponding speed\n",
    "2. Import speed to existing DataFrame matching racers by licence\n",
    "\n",
    "The `if` condition in the middle will exit this block of code once we hit the end of the Elite finishers, seeing as that's all we have in our existing data set so can't match anyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    cells = row.find_all( \"td\" )\n",
    "\n",
    "    speed = cells[7].text[:5]\n",
    "    licence = cells[4].text\n",
    "    bib = int( cells[1].text )\n",
    "    pos = cells[0].text[8:]\n",
    "    if \"\" == pos: break\n",
    "    # Match rider by UCI licence if present, otherwise fallback to bib\n",
    "    if len(df2.loc[df2['UciRiderId'] == licence].index.values ):\n",
    "        rid = int(df2.loc[df2['UciRiderId'] == licence].index.values[0])\n",
    "    else:\n",
    "        rid = int( df2.loc[df2['RaceNr'] == bib].index.values[0] )\n",
    "    df.loc[df['id'] == rid, 'speed'] = speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can take another look at how our data is looking, with the `speed` column now containing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bib</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>speed</th>\n",
       "      <th>split1</th>\n",
       "      <th>split2</th>\n",
       "      <th>split3</th>\n",
       "      <th>split4</th>\n",
       "      <th>split5</th>\n",
       "      <th>status</th>\n",
       "      <th>uci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>NICOLE Myriam</td>\n",
       "      <td>1</td>\n",
       "      <td>41.50</td>\n",
       "      <td>23.472</td>\n",
       "      <td>60.224</td>\n",
       "      <td>92.252</td>\n",
       "      <td>135.352</td>\n",
       "      <td>160.706</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10004535237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>ATHERTON Rachel</td>\n",
       "      <td>2</td>\n",
       "      <td>43.03</td>\n",
       "      <td>22.847</td>\n",
       "      <td>61.748</td>\n",
       "      <td>95.397</td>\n",
       "      <td>139.415</td>\n",
       "      <td>164.265</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10003434487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>SEAGRAVE Tahnee</td>\n",
       "      <td>3</td>\n",
       "      <td>42.89</td>\n",
       "      <td>22.902</td>\n",
       "      <td>61.248</td>\n",
       "      <td>95.686</td>\n",
       "      <td>139.696</td>\n",
       "      <td>164.484</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10007414016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>CABIROU Marine</td>\n",
       "      <td>4</td>\n",
       "      <td>42.03</td>\n",
       "      <td>24.295</td>\n",
       "      <td>63.484</td>\n",
       "      <td>97.391</td>\n",
       "      <td>140.362</td>\n",
       "      <td>165.935</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10009563069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2028</td>\n",
       "      <td>RAVANEL Cecile</td>\n",
       "      <td>5</td>\n",
       "      <td>42.03</td>\n",
       "      <td>24.986</td>\n",
       "      <td>63.606</td>\n",
       "      <td>97.407</td>\n",
       "      <td>142.042</td>\n",
       "      <td>168.416</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10002816317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bib    id             name  rank  speed  split1  split2  split3   split4  \\\n",
       "0    1  2001    NICOLE Myriam     1  41.50  23.472  60.224  92.252  135.352   \n",
       "1    4  2004  ATHERTON Rachel     2  43.03  22.847  61.748  95.397  139.415   \n",
       "2    2  2002  SEAGRAVE Tahnee     3  42.89  22.902  61.248  95.686  139.696   \n",
       "3    8  2008   CABIROU Marine     4  42.03  24.295  63.484  97.391  140.362   \n",
       "4   28  2028   RAVANEL Cecile     5  42.03  24.986  63.606  97.407  142.042   \n",
       "\n",
       "    split5    status          uci  \n",
       "0  160.706  Finished  10004535237  \n",
       "1  164.265  Finished  10003434487  \n",
       "2  164.484  Finished  10007414016  \n",
       "3  165.935  Finished  10009563069  \n",
       "4  168.416  Finished  10002816317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export\n",
    "\n",
    "All that's left is to save our data to CSV files so we can quickly import it again for analysis and visualization without making constant requests to the online servers. This not only reduces load on the services providing the data, but also allows us to work on our analysis \"offline\", moreover giving us a local copy in case the results are ever taken down. It's also much quicker to load data this way than constantly hitting online servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv( str(race) + '_' + raceName + '_' + gender + '.results.csv' )\n",
    "df2.to_csv( str(race) + '_' + raceName + '_' + gender + '.racers.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Credits\n",
    "\n",
    "### Author: Dominic Wrapson\n",
    "\n",
    "\n",
    "> **@domwrap**\n",
    "<br>\n",
    "<img src=\"https://png.icons8.com/material/24/000000/github-2.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/stackoverflow.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/linkedin.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/windows8.png\">\n",
    "<img src=\"https://png.icons8.com/ios-glyphs/24/000000/instagram-new.png\">\n",
    "<img src=\"https://png.icons8.com/material/24/000000/twitter.png\">\n",
    "<a href=\"https://medium.com/@domwrap\"><img src=\"https://png.icons8.com/material/24/000000/medium-logo.png\"></a>\n",
    ">\n",
    "> <img src=\"https://png.icons8.com/material/24/000000/home.png\"> http://dominic.wrapson.com\n",
    ">\n",
    "><img src=\"https://png.icons8.com/material/24/000000/cycling-mountain-bike.png\"> [Hwulex](https://www.pinkbike.com/u/Hwulex/)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Special Thanks\n",
    "\n",
    "Mark Shilton for the inspiration\n",
    "- http://lookatthestats.blogspot.ca\n",
    "- https://plus.google.com/+MarkShilton\n",
    "- https://dirtmountainbike.com/author/mrgeekstats\n",
    "\n",
    "\n",
    "<a href=\"https://icons8.com\">Icon pack by Icons8</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
